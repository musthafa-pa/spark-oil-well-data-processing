{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ac17f6-e932-4e06-9686-bde3172683b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatacamp Pyspark Tutorial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.memory.offHeap.enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.memory.offHeap.size\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10g\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1840d3dc-f829-411c-8a71-2f8bc919e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570ad7b4-5e4b-49eb-ad01-a2358b59e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/04 09:36:03 WARN Utils: Your hostname, admins-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.2 instead (on interface en0)\n",
      "24/08/04 09:36:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/04 09:36:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dc2b29-5531-484b-aa30-99d55edc8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/Users/musthafa/softway/DAI/spark/workspace/data/online_retail.csv.gz',header=True,escape=\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a6e576-ead6-4887-a9d2-675a4800c174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/10 8:26|2.55     |17850     |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/10 8:26|2.75     |17850     |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf97823-9533-46b1-9ff3-cfad4d222007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e678d7e-3c98-4094-81b9-101c3508a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4373"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('CustomerID').distinct().count() # Answer: 95\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f6fa80-d5ee-4fd7-948a-a2907a7c7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd30db02-3c2b-4aee-b1a6-977f4fbdad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|           Country|country_count|\n",
      "+------------------+-------------+\n",
      "|            Sweden|            8|\n",
      "|         Singapore|            1|\n",
      "|           Germany|           95|\n",
      "|               RSA|            1|\n",
      "|            France|           87|\n",
      "|            Greece|            4|\n",
      "|European Community|            1|\n",
      "|           Belgium|           25|\n",
      "|           Finland|           12|\n",
      "|             Malta|            2|\n",
      "|       Unspecified|            4|\n",
      "|             Italy|           15|\n",
      "|              EIRE|            3|\n",
      "|         Lithuania|            1|\n",
      "|            Norway|           10|\n",
      "|             Spain|           31|\n",
      "|           Denmark|            9|\n",
      "|         Hong Kong|            0|\n",
      "|            Israel|            4|\n",
      "|           Iceland|            1|\n",
      "+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').agg(countDistinct('CustomerID').alias('country_count')).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad633f29-a488-4257-a305-10f1210404b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76708e-aab5-4c19-8f8d-41495380dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae220ebf-99fc-4ee6-9a6b-9931bb3faf0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mClusteringEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictionCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeaturesCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstandardized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmetricName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msilhouette\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistanceMeasure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquaredEuclidean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      6\u001b[0m     KMeans_algo\u001b[38;5;241m=\u001b[39mKMeans(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandardized\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mi)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages/pyspark/__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m forces keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages/pyspark/ml/evaluation.py:930\u001b[0m, in \u001b[0;36mClusteringEvaluator.__init__\u001b[0;34m(self, predictionCol, featuresCol, metricName, distanceMeasure, weightCol)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m__init__(self, \\\\*, predictionCol=\"prediction\", featuresCol=\"features\", \\\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m         metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\", weightCol=None)\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28msuper\u001b[39m(ClusteringEvaluator, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_java_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.ml.evaluation.ClusteringEvaluator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muid\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDefault(metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilhouette\u001b[39m\u001b[38;5;124m\"\u001b[39m, distanceMeasure\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquaredEuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    934\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages/pyspark/ml/wrapper.py:80\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mReturns a new Java object.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     82\u001b[0m java_obj \u001b[38;5;241m=\u001b[39m _jvm()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m java_class\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cost = np.zeros(10)\n",
    "\n",
    "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='standardized',metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "\n",
    "for i in range(2,10):\n",
    "    KMeans_algo=KMeans(featuresCol='standardized', k=i)\n",
    "    KMeans_fit=KMeans_algo.fit(data_scale_output)\n",
    "    output=KMeans_fit.transform(data_scale_output)\n",
    "    cost[i] = KMeans_fit.summary.trainingCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e304937-27ff-4bad-bb81-26e36e107d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
